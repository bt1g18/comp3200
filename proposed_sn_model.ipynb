{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import collections\n",
    "import pickle\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sliding_window import sliding_window\n",
    "from cluster_eval import greedy_relabel\n",
    "from cluster_eval import brute_relabel\n",
    "from cluster_eval import print_results\n",
    "from cluster_eval import relabel_list\n",
    "from keras import layers\n",
    "\n",
    "# Hardcoded number of sensor channels employed in the OPPORTUNITY challenge\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "\n",
    "# Hardcoded number of classes in the gesture recognition problem\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Hardcoded length of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "\n",
    "# Length of the input sequence after convolutional operations\n",
    "FINAL_SEQUENCE_LENGTH = 6\n",
    "\n",
    "# Hardcoded step of the sliding window mechanism employed to segment the data\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Number filters convolutional layers\n",
    "NUM_FILTERS = 64\n",
    "\n",
    "# Size filters convolutional layers\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "# Number of unit in the long short-term recurrent layers\n",
    "NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file oppChallenge_locomotion.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n",
      "(465668, 113)\n",
      "(94260, 113)\n",
      "{0: 231751, 1: 130506, 2: 88883, 3: 14528}\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('oppChallenge_locomotion.data')\n",
    "\n",
    "def remove_class(X_train, y_train, X_test, y_test, class_n):\n",
    "    uy_train = y_train[y_train != class_n]\n",
    "    uX_train = X_train[y_train != class_n]\n",
    "    uy_test = y_test[y_test != class_n]\n",
    "    uX_test = X_test[y_test != class_n]\n",
    "    \n",
    "    classes = set(y_train)\n",
    "    \n",
    "    for x in range(class_n + 1, len(classes)):\n",
    "        uy_train[uy_train == x] = x - 1\n",
    "        uy_test[uy_test == x] = x - 1\n",
    "        \n",
    "    return uX_train, uy_train, uX_test, uy_test\n",
    "\n",
    "# def delete_features():\n",
    "# RKN^, RKN_, BACK, HIP, R-SHOE, L-SHOE\n",
    "# 53 Features\n",
    "\n",
    "#features_delete = np.arange(6, 15)\n",
    "#features_delete = np.concatenate([features_delete, np.arange(21, 36)])\n",
    "#features_delete = np.concatenate([features_delete, np.arange(45, 81)])\n",
    "\n",
    "# 60 Features\n",
    "#features_delete = np.arange(0, 6)\n",
    "#features_delete = np.concatenate([features_delete, np.arange(15, 21)])\n",
    "#features_delete = np.concatenate([features_delete, np.arange(36, 45)])\n",
    "#features_delete = np.concatenate([features_delete, np.arange(81, 113)])\n",
    "\n",
    "# 9 Features (BACK - Phone)\n",
    "#features_delete = np.arange(0, 36)\n",
    "#features_delete = np.concatenate([features_delete, np.arange(45, 113)])\n",
    "\n",
    "# 9 Features (RUA - Phone on Shoulder)\n",
    "#features_delete = np.arange(0, 45)\n",
    "#features_delete = np.concatenate([features_delete, np.arange(54, 113)])\n",
    "\n",
    "# 9 Features (RLA - Wrist Watch)\n",
    "#features_delete = np.arange(0, 54)\n",
    "#features_delete = np.concatenate([features_delete, np.arange(63, 113)])\n",
    "\n",
    "#X_train = np.delete(X_train, features_delete, 1)\n",
    "#X_test = np.delete(X_test, features_delete, 1)\n",
    "\n",
    "classes = [\"Null\", \"Stand\", \"Walk\" ,\"Sit\", \"Lie\"]\n",
    "\n",
    "# 0 - null | 1 - stand | 2 - walk | 3 - sit | 4 - lie\n",
    "\n",
    "X_train, y_train, X_test, y_test = remove_class(X_train, y_train, X_test, y_test, 0) # remove null\n",
    "classes.remove(\"Null\")\n",
    "\n",
    "# 0 - stand | 1 - walk | 2 - sit | 3 - lie\n",
    "\n",
    "#X_train, y_train, X_test, y_test = remove_class(X_train, y_train, X_test, y_test, 1) # remove walking\n",
    "#classes.remove(\"Walk\")\n",
    "\n",
    "#X_train, y_train, X_test, y_test = remove_class(X_train, y_train, X_test, y_test, 3) # remove walking\n",
    "#classes.remove(\"Lie\")\n",
    "\n",
    "#X_train, y_train, X_test, y_test = remove_class(X_train, y_train, X_test, y_test, 2) # remove walking\n",
    "#classes.remove(\"Sit\")\n",
    "\n",
    "# 0 - stand | 1 - sit | 2 - lie\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "label_dict = dict(zip(unique, counts))\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding window (testing): inputs (7854, 24, 113), targets (7854,)\n",
      "(38804, 24, 113)\n",
      "(7854, 24, 113)\n"
     ]
    }
   ],
   "source": [
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "#X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
    "#X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
    "#X_train = X_train.reshape((-1, 1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "#X_test = X_test.reshape((-1, 1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten sliding window\n",
    "\n",
    "def flatten_sliding_window(X_data):\n",
    "    return X_data.reshape(X_data.shape[0], (X_data.shape[1] * X_data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38804, 12, 339)\n",
      "(7854, 12, 339)\n"
     ]
    }
   ],
   "source": [
    "from kymatio.sklearn import Scattering1D\n",
    "\n",
    "scattering_transformer = Scattering1D(3, (113 * 24), 2) # (J, shape, Q) 3, 113*24, 2\n",
    "scat_train = scattering_transformer(flatten_sliding_window(X_train))\n",
    "scat_test = scattering_transformer(flatten_sliding_window(X_test))\n",
    "print(scat_train.shape)\n",
    "print(scat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38804, 4068)\n",
      "(7854, 4068)\n"
     ]
    }
   ],
   "source": [
    "scat_train = flatten_sliding_window(scat_train)\n",
    "scat_test = flatten_sliding_window(scat_test)\n",
    "print(scat_train.shape)\n",
    "print(scat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:\n",
      "84.12199258804321\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_CLUSTERS = 11\n",
    "\n",
    "# time the cluster\n",
    "start = time.time()\n",
    "\n",
    "y_pred = KMeans(n_clusters=NUMBER_OF_CLUSTERS, random_state=0).fit(scat_train).predict(scat_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time:\")\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "def greedy_relabel(y_pred, y_test):\n",
    "    # cluster -> counts of each true labels\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    label_dict = dict(zip(unique, counts))\n",
    "    counters = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    \n",
    "    for cluster, true in zip(y_pred, y_test):\n",
    "        counters[cluster][true] += 1\n",
    "        \n",
    "    relabels = {}\n",
    "    for cluster, counts in counters.items():\n",
    "        best = max(counts.items(), key=operator.itemgetter(1))[0]\n",
    "        relabels[cluster] = best\n",
    "        \n",
    "    l = sorted(list(relabels.items()), key=lambda a: a[0])\n",
    "    return [b for a, b in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Labels:\n",
      "[0, 2, 0, 0, 3, 0, 2, 1, 1, 0]\n",
      "\n",
      "F1:\n",
      "0.7383535146506889\n",
      "\n",
      "Accuracy:\n",
      "0.7210338680926917\n",
      "\n",
      "ARI:\n",
      "0.41578990563249013\n"
     ]
    }
   ],
   "source": [
    "uy_pred = y_pred.copy()\n",
    "clusters = list(set(y_pred))\n",
    "clusters.sort()\n",
    "\n",
    "relabels = brute_relabel(uy_pred, y_test)\n",
    "#relabels = greedy_relabel(uy_pred, y_test)\n",
    "#relabels = [0, 2, 1, 1, 2, 0, 0, 0, 3, 0]\n",
    "\n",
    "uy_pred = relabel_list(uy_pred, clusters, relabels)\n",
    "print_results(uy_pred, y_test, relabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = metrics.confusion_matrix(y_test, uy_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "disp = disp.plot()\n",
    "\n",
    "#plt.savefig('confusion_matricies/c4_f113_km11+sw24_12.png') # number of classes, features, method\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
